# Sub-Millisecond Check Design: <1ms P95 Target

---

> ### ğŸ“Š Performance Claims Disclaimer
>
> This document contains **performance projections and targets** that are:
> - âœ… Based on preliminary analysis and research
> - âœ… Informed by similar systems and benchmarks
> - âŒ NOT validated through prototyping
> - âŒ NOT guaranteed to be achievable
>
> **All performance claims require validation** through the phased prototyping and testing approach described in the RFC.
>
> See RFC-001 Performance Assumptions section for full details.

---

## Executive Summary

**Goal**: Achieve **target of <1ms P95 latency** for Check operations at edge nodes.

**Status:** âš ï¸ **Unvalidated Target** - Requires prototyping to confirm achievability

**Key Insight**: To hit <1ms, we must eliminate:
- Network hops (deploy edge in same namespace)
- Disk I/O (everything in memory)
- Graph traversal (pre-compute results)
- GC pauses (use Rust, not Go)
- Lock contention (lock-free structures)

---

## 1. Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              KUBERNETES CLUSTER                                     â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        APPLICATION NAMESPACE: app-a                         â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      localhost      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚  â”‚   Application   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   OpenFGA Edge  â”‚               â”‚   â”‚
â”‚  â”‚  â”‚   Pod           â”‚      (< 0.1ms)      â”‚   Sidecar       â”‚               â”‚   â”‚
â”‚  â”‚  â”‚                 â”‚                     â”‚                 â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ gRPC client  â”‚                     â”‚  â€¢ In-memory    â”‚               â”‚   â”‚
â”‚  â”‚  â”‚  â€¢ SDK          â”‚                     â”‚  â€¢ Pre-computed â”‚               â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚  â€¢ App-specific â”‚               â”‚   â”‚
â”‚  â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        APPLICATION NAMESPACE: app-b                         â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      localhost      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚   â”‚
â”‚  â”‚  â”‚   Application   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   OpenFGA Edge  â”‚               â”‚   â”‚
â”‚  â”‚  â”‚   Pod           â”‚                     â”‚   Sidecar       â”‚               â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                      â”‚                             â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚                         â”‚        Async Sync          â”‚                â”‚            â”‚
â”‚                         â”‚        (Kafka/gRPC)        â”‚                â”‚            â”‚
â”‚                         â–¼                            â–¼                â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                        OPENFGA NAMESPACE (Central)                          â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚   â”‚
â”‚  â”‚  â”‚                     OpenFGA Central Cluster                         â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   Primary    â”‚  â”‚   Replica    â”‚  â”‚   Replica    â”‚              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â”‚   (R/W)      â”‚  â”‚   (R)        â”‚  â”‚   (R)        â”‚              â”‚   â”‚   â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚  â”‚  PostgreSQL     â”‚  â”‚  Kafka/NATS     â”‚  â”‚  Pre-compute    â”‚             â”‚   â”‚
â”‚  â”‚  â”‚  (Full Data)    â”‚  â”‚  (CDC Stream)   â”‚  â”‚  Workers        â”‚             â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Why <1ms is Achievable

### 2.1 Latency Budget Breakdown

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         LATENCY BUDGET: 1ms Total                                   â”‚
â”‚                                                                                     â”‚
â”‚  Component                          â”‚ Current (Go) â”‚ Target (Rust) â”‚ Technique     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  Network (localhost)                â”‚    0.05ms    â”‚    0.05ms     â”‚ Unix socket   â”‚
â”‚  gRPC deserialization               â”‚    0.10ms    â”‚    0.02ms     â”‚ Zero-copy     â”‚
â”‚  Request validation                 â”‚    0.05ms    â”‚    0.01ms     â”‚ Compile-time  â”‚
â”‚  Cache lookup                       â”‚    0.20ms    â”‚    0.05ms     â”‚ Lock-free map â”‚
â”‚  Hash computation                   â”‚    0.05ms    â”‚    0.02ms     â”‚ xxhash/SIMD   â”‚
â”‚  Graph traversal                    â”‚   5-50ms     â”‚    0.00ms     â”‚ Pre-computed! â”‚
â”‚  Response serialization             â”‚    0.10ms    â”‚    0.02ms     â”‚ Zero-copy     â”‚
â”‚  GC pause (worst case)              â”‚   1-10ms     â”‚    0.00ms     â”‚ No GC (Rust)  â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚  TOTAL (P95)                        â”‚   10-50ms    â”‚   <0.20ms     â”‚               â”‚
â”‚  TOTAL (P99)                        â”‚   50-100ms   â”‚   <0.50ms     â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Key Techniques

| Technique | Latency Saved | How |
|-----------|---------------|-----|
| **Pre-computed results** | 5-50ms | No graph traversal at request time |
| **In-memory only** | 1-5ms | No disk I/O |
| **Rust (no GC)** | 1-10ms | Eliminates GC pauses |
| **Lock-free HashMap** | 0.1-0.5ms | No mutex contention |
| **Unix domain socket** | 0.1-0.2ms | No TCP overhead |
| **Zero-copy parsing** | 0.1ms | No allocation on hot path |

---

## 3. Edge Sidecar Design

### 3.1 What Gets Pre-Computed?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PRE-COMPUTATION STRATEGY                                    â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚   CENTRAL (async, can be slow)           EDGE (sync, must be fast)         â”‚   â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€           â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€        â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚   1. Receive tuple write                 1. Receive pre-computed result    â”‚   â”‚
â”‚  â”‚   2. Store in PostgreSQL                 2. Update in-memory HashMap       â”‚   â”‚
â”‚  â”‚   3. Trigger pre-computation             3. Check = HashMap.get()          â”‚   â”‚
â”‚  â”‚   4. For affected (object, relation):                                      â”‚   â”‚
â”‚  â”‚      - Compute all users with access     Time: O(1) lookup                 â”‚   â”‚
â”‚  â”‚      - OR compute specific checks                                          â”‚   â”‚
â”‚  â”‚   5. Publish to Kafka                                                      â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â”‚   Time: O(graph_depth), async            Time: O(1), sync                  â”‚   â”‚
â”‚  â”‚                                                                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  Two Pre-Computation Modes:                                                        â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  MODE A: Full Materialization   â”‚  â”‚  MODE B: Hot-Path Materialization       â”‚  â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚  Pre-compute ALL possible       â”‚  â”‚  Pre-compute only frequently            â”‚  â”‚
â”‚  â”‚  (user, relation, object)       â”‚  â”‚  checked combinations                   â”‚  â”‚
â”‚  â”‚  combinations                   â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  â€¢ Track access patterns                â”‚  â”‚
â”‚  â”‚  Pros:                          â”‚  â”‚  â€¢ Pre-compute top 95%                  â”‚  â”‚
â”‚  â”‚  â€¢ Always O(1)                  â”‚  â”‚  â€¢ Fallback to central for rest         â”‚  â”‚
â”‚  â”‚  â€¢ No cache miss                â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  Pros:                                  â”‚  â”‚
â”‚  â”‚  Cons:                          â”‚  â”‚  â€¢ Lower storage                        â”‚  â”‚
â”‚  â”‚  â€¢ High storage (NÃ—MÃ—R)         â”‚  â”‚  â€¢ Faster sync                          â”‚  â”‚
â”‚  â”‚  â€¢ Slow sync on changes         â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  Cons:                                  â”‚  â”‚
â”‚  â”‚  Best for:                      â”‚  â”‚  â€¢ ~5% cache miss (fallback)            â”‚  â”‚
â”‚  â”‚  â€¢ Small user/object counts     â”‚  â”‚                                         â”‚  â”‚
â”‚  â”‚  â€¢ Static permissions           â”‚  â”‚  Best for:                              â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  â€¢ Large scale                          â”‚  â”‚
â”‚  â”‚                                 â”‚  â”‚  â€¢ Predictable access patterns          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Data Structure at Edge

```rust
use dashmap::DashMap;  // Lock-free concurrent HashMap
use std::sync::Arc;

/// Pre-computed check result
#[derive(Clone, Copy)]
pub struct CheckResult {
    pub allowed: bool,
    pub computed_at: u64,  // Timestamp for staleness check
}

/// Edge sidecar state - entirely in memory
pub struct EdgeState {
    /// Primary lookup: (store, object, relation, user) -> allowed
    /// Key is pre-hashed for O(1) lookup
    check_cache: DashMap<u64, CheckResult>,  // ~40 bytes per entry

    /// Authorization models (small, always cached)
    models: DashMap<String, Arc<AuthModel>>,

    /// Sync watermark per store
    watermarks: DashMap<String, u64>,

    /// Metrics
    hit_count: AtomicU64,
    miss_count: AtomicU64,
}

impl EdgeState {
    /// Check operation - O(1) hash lookup
    /// Target: <0.2ms P95
    pub fn check(&self, req: &CheckRequest) -> CheckOutcome {
        let key = self.compute_key(req);

        match self.check_cache.get(&key) {
            Some(result) => {
                self.hit_count.fetch_add(1, Ordering::Relaxed);
                CheckOutcome::Hit(result.allowed)
            }
            None => {
                self.miss_count.fetch_add(1, Ordering::Relaxed);
                CheckOutcome::Miss  // Caller should forward to central
            }
        }
    }

    /// Hash key computation - must be fast
    #[inline]
    fn compute_key(&self, req: &CheckRequest) -> u64 {
        // xxhash is ~3GB/s, so 100 bytes = 0.03 microseconds
        let mut hasher = xxhash_rust::xxh3::Xxh3::new();
        hasher.update(req.store_id.as_bytes());
        hasher.update(req.object.as_bytes());
        hasher.update(req.relation.as_bytes());
        hasher.update(req.user.as_bytes());
        hasher.digest()
    }

    /// Batch update from sync stream
    pub fn apply_updates(&self, updates: Vec<CheckUpdate>) {
        for update in updates {
            let key = self.compute_key_from_update(&update);
            if update.deleted {
                self.check_cache.remove(&key);
            } else {
                self.check_cache.insert(key, CheckResult {
                    allowed: update.allowed,
                    computed_at: update.timestamp,
                });
            }
        }
    }
}

pub enum CheckOutcome {
    Hit(bool),   // Return immediately
    Miss,        // Forward to central
}
```

### 3.3 Memory Estimation

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         MEMORY REQUIREMENTS                                         â”‚
â”‚                                                                                     â”‚
â”‚  Per check result entry:                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Key (u64 hash):           8 bytes                                          â”‚   â”‚
â”‚  â”‚  Value (CheckResult):      9 bytes (1 bool + 8 timestamp)                   â”‚   â”‚
â”‚  â”‚  DashMap overhead:        ~24 bytes                                         â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                                          â”‚   â”‚
â”‚  â”‚  Total per entry:         ~41 bytes â†’ round to 48 bytes                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                                     â”‚
â”‚  Example Scenarios:                                                                â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Scenario            â”‚ Check Count â”‚ Memory     â”‚ Notes                      â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ Small app           â”‚ 100K        â”‚ 4.8 MB     â”‚ 1K users Ã— 100 objects     â”‚  â”‚
â”‚  â”‚ Medium app          â”‚ 1M          â”‚ 48 MB      â”‚ 10K users Ã— 100 objects    â”‚  â”‚
â”‚  â”‚ Large app           â”‚ 10M         â”‚ 480 MB     â”‚ 100K users Ã— 100 objects   â”‚  â”‚
â”‚  â”‚ Very large app      â”‚ 100M        â”‚ 4.8 GB     â”‚ Hot-path mode recommended  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                     â”‚
â”‚  Hot-Path Mode (95% coverage):                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Very large app      â”‚ 10M (hot)   â”‚ 480 MB     â”‚ 95% hit rate, 5% fallback  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Sync Protocol

### 4.1 Application-Specific Subscription

```yaml
# Edge sidecar configuration per application
edge:
  application_id: "app-a"

  # Subscribe only to stores this app needs
  subscriptions:
    - store_id: "store_app_a_prod"
      mode: "full"           # Pre-compute everything

    - store_id: "store_shared"
      mode: "hot_path"       # Only frequently accessed
      hot_path_config:
        min_access_count: 10
        window: "1h"

  # Central connection
  central:
    endpoint: "openfga-central.openfga.svc:8081"

  # Sync settings
  sync:
    protocol: "grpc_stream"  # or "kafka"
    batch_size: 1000
    max_lag_ms: 5000         # Alert if sync lags > 5s

  # Memory limits
  memory:
    max_entries: 10_000_000
    eviction_policy: "lru"   # When limit hit, evict LRU
```

### 4.2 Sync Message Format

```protobuf
// Efficient sync protocol
message CheckResultSync {
    string store_id = 1;

    // Batch of pre-computed results
    repeated CheckResultUpdate updates = 2;

    // Watermark for exactly-once delivery
    uint64 watermark = 3;
}

message CheckResultUpdate {
    // Pre-hashed key (computed at central)
    uint64 key_hash = 1;

    // Original key components (for debugging/verification)
    string object = 2;
    string relation = 3;
    string user = 4;

    // Result
    bool allowed = 5;
    bool deleted = 6;  // If true, remove from cache

    // Timestamp
    uint64 computed_at = 7;
}
```

### 4.3 Central Pre-Computation Worker

```rust
/// Runs in central, computes check results on tuple changes
pub struct PreComputeWorker {
    datastore: Arc<dyn OpenFGADatastore>,
    check_resolver: Arc<dyn CheckResolver>,
    publisher: Arc<dyn SyncPublisher>,
}

impl PreComputeWorker {
    /// Called when tuples change
    pub async fn on_tuple_change(&self, change: TupleChange) {
        // 1. Determine affected checks
        let affected = self.find_affected_checks(&change).await;

        // 2. Re-compute each affected check
        let mut updates = Vec::new();
        for check_key in affected {
            let result = self.check_resolver.resolve(&check_key).await;
            updates.push(CheckResultUpdate {
                key_hash: hash(&check_key),
                object: check_key.object,
                relation: check_key.relation,
                user: check_key.user,
                allowed: result.allowed,
                deleted: false,
                computed_at: now(),
            });
        }

        // 3. Publish to sync stream (partitioned by store_id)
        self.publisher.publish(CheckResultSync {
            store_id: change.store_id,
            updates,
            watermark: change.ulid,
        }).await;
    }

    /// Find all (object, relation, user) combinations affected by a tuple change
    async fn find_affected_checks(&self, change: &TupleChange) -> Vec<CheckKey> {
        // For direct tuples: only the specific (object, relation, user)
        // For computed relations: need to traverse the graph
        // This is the expensive part - but it's async, not on critical path

        match self.get_rewrite_type(&change.tuple) {
            RewriteType::Direct => {
                // Simple case: only one check affected
                vec![CheckKey::from_tuple(&change.tuple)]
            }
            RewriteType::ComputedUserset | RewriteType::TupleToUserset => {
                // Complex case: find all affected users
                self.expand_affected_users(&change.tuple).await
            }
        }
    }
}
```

---

## 5. Request Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              CHECK REQUEST FLOW                                     â”‚
â”‚                                                                                     â”‚
â”‚  Application                     Edge Sidecar                    Central           â”‚
â”‚      â”‚                               â”‚                               â”‚             â”‚
â”‚      â”‚  Check(object, relation,      â”‚                               â”‚             â”‚
â”‚      â”‚        user)                  â”‚                               â”‚             â”‚
â”‚      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                               â”‚             â”‚
â”‚      â”‚     (Unix socket, ~0.05ms)    â”‚                               â”‚             â”‚
â”‚      â”‚                               â”‚                               â”‚             â”‚
â”‚      â”‚                          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                          â”‚             â”‚
â”‚      â”‚                          â”‚ Compute â”‚                          â”‚             â”‚
â”‚      â”‚                          â”‚  Hash   â”‚                          â”‚             â”‚
â”‚      â”‚                          â”‚ (~0.02ms)                          â”‚             â”‚
â”‚      â”‚                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚             â”‚
â”‚      â”‚                               â”‚                               â”‚             â”‚
â”‚      â”‚                          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”                          â”‚             â”‚
â”‚      â”‚                          â”‚ HashMap â”‚                          â”‚             â”‚
â”‚      â”‚                          â”‚  .get() â”‚                          â”‚             â”‚
â”‚      â”‚                          â”‚ (~0.05ms)                          â”‚             â”‚
â”‚      â”‚                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                          â”‚             â”‚
â”‚      â”‚                               â”‚                               â”‚             â”‚
â”‚      â”‚                         â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”                         â”‚             â”‚
â”‚      â”‚                         â”‚  HIT?     â”‚                         â”‚             â”‚
â”‚      â”‚                         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                         â”‚             â”‚
â”‚      â”‚                               â”‚                               â”‚             â”‚
â”‚      â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚             â”‚
â”‚      â”‚              â”‚ YES            â”‚            NO  â”‚              â”‚             â”‚
â”‚      â”‚              â–¼                â”‚                â–¼              â”‚             â”‚
â”‚      â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚             â”‚
â”‚      â”‚         â”‚ Return  â”‚           â”‚           â”‚ Forward â”‚         â”‚             â”‚
â”‚      â”‚         â”‚ Result  â”‚           â”‚           â”‚ to      â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚             â”‚
â”‚      â”‚         â”‚ (~0.02ms)           â”‚           â”‚ Central â”‚         â”‚             â”‚
â”‚      â”‚         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜           â”‚           â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â”‚             â”‚
â”‚      â”‚              â”‚                â”‚                â”‚              â”‚             â”‚
â”‚      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚                â”‚              â”‚             â”‚
â”‚      â”‚                               â”‚                â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚             â”‚
â”‚      â”‚  Total: <0.2ms (P95)          â”‚                â”‚  (~10-50ms)  â”‚             â”‚
â”‚      â”‚                               â”‚                â”‚              â”‚             â”‚
â”‚      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚             â”‚
â”‚      â”‚                               â”‚   (cache result locally)      â”‚             â”‚
â”‚      â”‚  Total with miss: ~50ms       â”‚                               â”‚             â”‚
â”‚                                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 6. Rust Edge Implementation

### 6.1 Minimal Edge Server

```rust
use dashmap::DashMap;
use tonic::{transport::Server, Request, Response, Status};
use std::sync::Arc;

pub mod openfga {
    tonic::include_proto!("openfga.v1");
}

use openfga::{
    openfga_service_server::{OpenFgaService, OpenFgaServiceServer},
    CheckRequest, CheckResponse,
};

/// Ultra-fast edge service
pub struct EdgeService {
    state: Arc<EdgeState>,
    central_client: openfga::openfga_service_client::OpenFgaServiceClient<tonic::transport::Channel>,
}

#[tonic::async_trait]
impl OpenFgaService for EdgeService {
    /// Check - target <0.2ms P95
    async fn check(
        &self,
        request: Request<CheckRequest>,
    ) -> Result<Response<CheckResponse>, Status> {
        let req = request.into_inner();

        // O(1) lookup in pre-computed cache
        match self.state.check(&req) {
            CheckOutcome::Hit(allowed) => {
                Ok(Response::new(CheckResponse { allowed }))
            }
            CheckOutcome::Miss => {
                // Forward to central (rare path)
                let response = self.central_client
                    .clone()
                    .check(Request::new(req))
                    .await?;

                // Cache the result for next time
                self.state.cache_result(&req, response.get_ref().allowed);

                Ok(response)
            }
        }
    }

    /// BatchCheck - parallel lookups
    async fn batch_check(
        &self,
        request: Request<BatchCheckRequest>,
    ) -> Result<Response<BatchCheckResponse>, Status> {
        let req = request.into_inner();
        let mut results = Vec::with_capacity(req.checks.len());
        let mut misses = Vec::new();

        // First pass: check local cache (parallel)
        for (i, check) in req.checks.iter().enumerate() {
            match self.state.check(check) {
                CheckOutcome::Hit(allowed) => {
                    results.push((i, allowed, None));
                }
                CheckOutcome::Miss => {
                    misses.push((i, check.clone()));
                }
            }
        }

        // Second pass: batch forward misses to central
        if !misses.is_empty() {
            let miss_results = self.central_client
                .clone()
                .batch_check(/* ... */)
                .await?;

            // Merge results
            for (i, result) in miss_results {
                results.push((i, result.allowed, Some(result)));
            }
        }

        // Sort by original index and return
        results.sort_by_key(|(i, _, _)| *i);
        Ok(Response::new(BatchCheckResponse {
            results: results.into_iter().map(|(_, allowed, _)| allowed).collect(),
        }))
    }

    // Write operations - always forward to central
    async fn write(&self, request: Request<WriteRequest>) -> Result<Response<WriteResponse>, Status> {
        self.central_client.clone().write(request).await
    }

    // ... other methods forward to central
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    let state = Arc::new(EdgeState::new());

    // Start sync task
    let sync_state = state.clone();
    tokio::spawn(async move {
        sync_from_central(sync_state).await;
    });

    // Start gRPC server on Unix socket for lowest latency
    let uds = tokio::net::UnixListener::bind("/tmp/openfga-edge.sock")?;
    let uds_stream = tokio_stream::wrappers::UnixListenerStream::new(uds);

    Server::builder()
        .add_service(OpenFgaServiceServer::new(EdgeService { state, central_client }))
        .serve_with_incoming(uds_stream)
        .await?;

    Ok(())
}
```

### 6.2 Benchmark Results (Expected)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         EXPECTED PERFORMANCE                                        â”‚
â”‚                                                                                     â”‚
â”‚  Test: 1M random Check requests, 95% cache hit rate                                â”‚
â”‚  Hardware: 2 CPU cores, 512MB RAM                                                  â”‚
â”‚                                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                                                                              â”‚  â”‚
â”‚  â”‚   Metric          â”‚  Go (Current)  â”‚  Rust Edge   â”‚  Improvement            â”‚  â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚   P50 Latency     â”‚     5ms        â”‚    0.08ms    â”‚    62x faster           â”‚  â”‚
â”‚  â”‚   P95 Latency     â”‚    25ms        â”‚    0.15ms    â”‚   166x faster           â”‚  â”‚
â”‚  â”‚   P99 Latency     â”‚    50ms        â”‚    0.40ms    â”‚   125x faster           â”‚  â”‚
â”‚  â”‚   P99.9 Latency   â”‚   100ms        â”‚    0.80ms    â”‚   125x faster           â”‚  â”‚
â”‚  â”‚   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€    â”‚  â”‚
â”‚  â”‚   Throughput      â”‚   10K/s        â”‚   500K/s     â”‚    50x higher           â”‚  â”‚
â”‚  â”‚   Memory (10M)    â”‚   2GB          â”‚   500MB      â”‚     4x less             â”‚  â”‚
â”‚  â”‚   CPU (at 10K/s)  â”‚   100%         â”‚    10%       â”‚    10x less             â”‚  â”‚
â”‚  â”‚                                                                              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                                     â”‚
â”‚  Cache Miss Penalty (5% of requests):                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Miss Latency: 10-50ms (network to central)                                 â”‚  â”‚
â”‚  â”‚   Overall P95 with 5% miss: 0.15ms Ã— 0.95 + 25ms Ã— 0.05 = 1.39ms            â”‚  â”‚
â”‚  â”‚   Still under 2ms target if miss rate stays < 5%                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 7. Deployment Configuration

### 7.1 Kubernetes Sidecar

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-app
  namespace: app-a
spec:
  containers:
  # Main application
  - name: app
    image: my-app:latest
    env:
    - name: OPENFGA_ENDPOINT
      value: "unix:///tmp/openfga-edge.sock"  # Unix socket for <0.1ms
    volumeMounts:
    - name: openfga-socket
      mountPath: /tmp

  # OpenFGA Edge sidecar
  - name: openfga-edge
    image: openfga/openfga-edge-rust:latest
    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"
    env:
    - name: OPENFGA_CENTRAL_ENDPOINT
      value: "openfga-central.openfga.svc:8081"
    - name: OPENFGA_STORE_IDS
      value: "store_app_a_prod"
    - name: OPENFGA_SYNC_MODE
      value: "full"  # or "hot_path"
    - name: OPENFGA_MAX_ENTRIES
      value: "1000000"
    volumeMounts:
    - name: openfga-socket
      mountPath: /tmp

  volumes:
  - name: openfga-socket
    emptyDir: {}
```

### 7.2 Helm Values

```yaml
# values.yaml for app-a
openfga:
  edge:
    enabled: true
    image: openfga/openfga-edge-rust:latest

    stores:
      - id: "store_app_a_prod"
        mode: "full"

    resources:
      requests:
        memory: "256Mi"
        cpu: "100m"
      limits:
        memory: "512Mi"
        cpu: "500m"

    central:
      endpoint: "openfga-central.openfga.svc:8081"

    metrics:
      enabled: true
      port: 9090
```

---

## 8. Monitoring & Alerts

```yaml
# Prometheus alerts for edge sidecars
groups:
- name: openfga-edge
  rules:
  # Alert if P95 > 1ms
  - alert: OpenFGAEdgeLatencyHigh
    expr: histogram_quantile(0.95, openfga_edge_check_duration_seconds_bucket) > 0.001
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "OpenFGA Edge P95 latency > 1ms"

  # Alert if cache hit rate < 90%
  - alert: OpenFGAEdgeCacheHitLow
    expr: |
      rate(openfga_edge_check_hit_total[5m]) /
      (rate(openfga_edge_check_hit_total[5m]) + rate(openfga_edge_check_miss_total[5m])) < 0.90
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "OpenFGA Edge cache hit rate < 90%"

  # Alert if sync lag > 10s
  - alert: OpenFGAEdgeSyncLag
    expr: openfga_edge_sync_lag_seconds > 10
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "OpenFGA Edge sync lag > 10s"
```

---

## 9. Summary

### Achieving <1ms P95

| Requirement | Solution |
|-------------|----------|
| No graph traversal | Pre-compute at central, O(1) lookup at edge |
| No GC pauses | Rust implementation |
| No network latency | Unix domain socket (same pod) |
| No lock contention | DashMap (lock-free HashMap) |
| No disk I/O | Everything in memory |

### Trade-offs

| Trade-off | Mitigation |
|-----------|-----------|
| Staleness (sync lag) | Bounded staleness consistency (configurable) |
| Memory usage | Hot-path mode for large datasets |
| Cache miss latency | Pre-warm cache, high hit rate target |
| Write complexity | Async pre-computation at central |

### Expected Results

| Metric | Target | Expected |
|--------|--------|----------|
| P50 Latency | <0.5ms | 0.08ms |
| **P95 Latency** | **<1ms** | **0.15ms** |
| P99 Latency | <2ms | 0.40ms |
| Cache Hit Rate | >95% | 95-99% |
| Throughput (per edge) | 10K/s | 500K/s |

---

*Document Version: 1.0*
*Last Updated: 2025-12-31*
